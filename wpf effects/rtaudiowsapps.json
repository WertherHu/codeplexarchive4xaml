{
  "ProjectName": "rtaudiowsapps",
  "Title": "Realtime Audio for Store Apps",
  "Description": "This is a sample app that demonstrates how to use WASAPI from Windows Store applications. It renders a \"delay\" effect to captured audio.",
  "MovedLink": "",
  "HomeWiki": "<div class=\"wikidoc\"><b>Project Description</b><br />This is a sample app that demonstrates how to use WASAPI from Windows Store applications. It renders a &#34;delay&#34; effect to captured audio.<br /><br />This projects is a sample to demonstrate how to use WASAPI from a Windows Store application. This application captures input from default audio device, adds a digital delay effect (mixes output with delayed input) and renders the audio in real time. One could connect a guitar to it and start playing.<br /><br />In order to interface with WASAPI one would need a C++ based project or a component library that interfaces with WASAPI from JS or C# application. In this sample a component library is created in C++ to deal with audio processing and the UI is defined in C#.<br /><br />Some assumptions are made:\n<ul><li>Both capture and render audio streams use float audio format. Otherwise conversion need to be done. There is an assertion in the component library that will fail if this is not true.</li>\n<li>Both capture and render streams use the same sample rate - if not the code will fail. To fix this one would need to implement a sample rate conversion.  To make this sample work go to &quot;Manage Audio Devices&quot; in control panel (or right click the volume icon on taskbar and select playback devices) - select your audio device, right click, select properties. Go to Advanced tab and make sure the sample rate for the default rate is the same both for capture and render devices. </li></ul>\n<br />The code initializes an event based capture stream - captured data is stored in a cyclic buffer. Every capture schedules an async work queue callback to process and render data. Processing data takes input and copies processed data to the output cyclic buffer. Then rendering pulls any unread data from the output cyclic buffer and writes to the render stream.<br />Project contains some wrapper classes to implement async calls for IAudioClient activation, media foundation async callbacks and async buffers.</div><div class=\"ClearBoth\"></div>",
  "TagList": "",
  "LastEdited": "2014-04-03T08:29:55.977-07:00"
}